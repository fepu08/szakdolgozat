# Thesis MVP

In this application, I aim to represent how recommendations are made for web applications using a service-oriented architecture.

This application was developed as a part of my thesis in 2024.

## API Documentation

You can find a postman collection as the documentation of API endpoints. It's location is: `./docs/Thesis-MVP-API.postman_collection.json`.

## Local Run/Development

### Prerequisites

Docker should be installed and running on your machine, see: [Install Docker Engine](https://docs.docker.com/engine/install/)

### Initial Setup for First-Time App Start with Docker Compose

When starting the application for the first time using `./docker-up.sh` or `docker compose up`, you might encounter an issue where the `intelligent-service` fails to connect to the database. This failure typically occurs because the database initialization, using the scripts provided, can take a few minutes to complete, during which `intelligent-service` attempts to connect and subsequently crashes due to the unavailability of the database.Ë™

To prevent this issue run the database initialization script before your first application start use either:

- `./docker-init-db.sh` shell script, or
- `docker compose --env-file .env.dev up -d db` docker compose CLI command.

### Using Docker CLI

- To _start_ execute: `docker compose up -d --build`
- To _stop_ execute: `docker compose down`

### Using Script files

#### Terminals

- On UNIX like operating system

  - make them executable `chmod +x docker-up.sh && chmod +x docker-down.sh`

- On Windows use `git bash`

#### Execution scripts

- To _start_ execute: `./docker-up.sh`
- To _stop_ execute: `./docker-down.sh`

## Generating SQL Scripts from CSV Data

This guide details the process of generating SQL scripts from CSV data for initializing a PostgreSQL database with data from the _ml-latest-small_ dataset.

### Directory Structure

- The `./init-db` directory contains SQL script files necessary for database initialization:
  - `./1-create-tables.sql`: Script to create database tables.
  - `./2-insert-610-dummy-users.sql`: Script to insert dummy user data.
  - `./3-insert-movies-genres.sql`: Script to insert movies and genres data.
  - `./4-insert-ratings.sql`: Script to insert ratings.

### Database Feed Script Generation and Preprocessing

**These steps are NOT required in order to run the application**, because all necessary script are already provided in `init-db` folder.

The scripts inside `./intelligent-service/data/scripts` are provided to create database feed scripts from `ml-latest-small` (located in `./intelligent-service/data/ml-latest-small`) CSV files. But it won't generate `./init-db/1-insert-tables.sql` files, so if your CSV files uses different file structure it might does not work well.

Python scripts located in `./intelligent-service/data/scripts` are used for data preprocessing and script generation:

- `separate-release-year-from-title.py`: Preprocesses the dataset by separating the release year from the movie title, resulting in a modified CSV file. This step is crucial for correctly formatting movie titles and years for subsequent SQL script generation.
- `generate-sql-script-to-create-dummy-users.py`: Generates the script to insert dummy users.
- `generate-sql-script-to-insert-data-into-movies-genres-and-movie-genres.py`: Generates the script to insert movies and genres data.
- `generate-sql-script-to-insert-data-into-ratings.py`: Generates the script to insert ratings.

### Output

- The modified CSV file, with release years separated from movie titles, is generated by `separate-release-year-from-title.py`, this file rename original `movies.csv` to `movies-original.csv` and creates new CSV named `movies.csv`
- Generated SQL scripts are saved to `./intelligent-service/data/scripts/generated-sql-scripts`. For database setup, these scripts have been moved manually to the `./init-db` folder.

### Usage

Again **these steps are NOT required in order to run the application**, because all necessary script are already provided in `init-db` folder.

To prepare and initialize your PostgreSQL database, follow these steps:

1. Ensure the _movielens ml-latest-small_ dataset is placed in the correct directory (the repository contains it by default).
2. Run `separate-release-year-from-title.py` to preprocess the dataset by separating movie titles and their release years.
3. Execute the other Python scripts (separately or with `run-scripts.sh`) to generate necessary SQL scripts if not already generated.
4. Move the generated SQL scripts into the `./init-db` folder if needed.
5. Execute the SQL scripts in your PostgreSQL environment in the order listed above.

# Disclaimer

This project is only for educational purposes. I utilize an external data source to generate ratings. The dataset, known as **MovieLens**, was created by [GroupLens Research](https://grouplens.org/datasets/movielens/). All rights reserved by the owner of the dataset.

You can download the original dataset, which was available at the time this project was created, in a ZIP file from `./intelligent-service-data-ml-latest-small.zip`.
